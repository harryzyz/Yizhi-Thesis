\documentclass[]{elsarticle}
%\setlength{\marginparwidth}{0.5in}
\usepackage{amsmath,amssymb,amsthm,mathtools,bbm,booktabs,array,tikz,pifont,comment,multirow,url,graphicx}
\input FJHDef.tex

%Requires ApproxUnivariate_k.tex, univariate_integration_k.tex, ConesPaperSpikyquad.eps, ConesPaperFlukyquad.eps

\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\INT}{INT}
\DeclareMathOperator{\APP}{APP}
\DeclareMathOperator{\lin}{lin}
\DeclareMathOperator{\up}{up}
\DeclareMathOperator{\lo}{lo}
\DeclareMathOperator{\fix}{fix}
\DeclareMathOperator{\err}{err}
\DeclareMathOperator{\maxcost}{maxcost}
\DeclareMathOperator{\mincost}{mincost}
\newcommand{\herr}{\widehat{\err}}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{algo}{Algorithm}
\newtheorem{condit}{Condition}
%\newtheorem{assump}{Assumption}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\Fnorm}[1]{\abs{#1}_{\cf}}
\newcommand{\Ftnorm}[1]{\abs{#1}_{\tcf}}
\newcommand{\Gnorm}[1]{\norm[\cg]{#1}}
\newcommand{\flin}{f_{\text{\rm{lin}}}}

\journal{Journal of Complexity}

\begin{document}

The algorithms used in this section on integration and the next section on function recovery are all based on quadratic splines on $[0,1]$.  The node set and the quadratic spline algorithm using $n$ function values are defined for $n \in \mathcal{I}:=\{3,5,7, \ldots\}$ as follows:
\begin{subequations} \label{linearspline}
\begin{equation}
x_i=\frac{i-1}{n-1}, \qquad i=1, \ldots, n,
\end{equation}
\begin{multline}
A_{n}(f)(x):=\frac{(n-1)^2}{2} \left[ f(x_{i})(x-x_{i+1})(x-x_{i+2})\right. \\\left.- 2f(x_{i+1})(x-x_{i})(x-x_{i+2}) +f(x_{i+2})(x-x_i)(x-x_{i+1}) \right] \\ \text{for }x_i \leq x \leq x_{i+2}.
\end{multline}
\end{subequations}
The cost of each function value is one and so the cost of  $A_n$ is $n$. The algorithm $A_n$ is imbedded in the algorithm $A_{3n-2}$, which uses $3n-3$ subintervals.  Thus, $r=3$ is the cost multiple.

The problem to be solved is univariate integration on the unit interval, $S(f):=\INT(f):=\int_{0}^{1}f(x) \, \dif x \in \cg := \reals$.  The fixed cost building blocks to construct the adaptive integration algorithm are the composite Simpson's rules based on $n-1$ intervals:
\begin{multline}
    P_{n}(f) := \int_0^1 A_n(f) \, \dif x \\
    =\frac{1}{3n-3}[f(x_1)+4f(x_2)+2f(x_3)+4f(x_4)+2f(x_5)\cdots+4f(x_{n-1})+f(x_n)].
\end{multline}

The space of input functions is $\cf:=\mathcal{V}^{3}$, the space of functions whose third derivatives have finite variation.  The general definitions of some relevant norms and spaces are as follows:
\begin{subequations} \label{defSobolev}
\begin{gather}
\Var(f) := \sup_{\substack{n \in \naturals\\ 0 = x_0 < x_1 < \cdots < x_{n} =1}} \sum_{i=1}^n \abs{f(x_i)-f(x_{i-1})}, \\
\norm[p]{f}:= \begin{cases} \displaystyle \left[\int_0^1 \abs{f(x)}^p \, \dif x \right]^{1/p}, & 1 \le p < \infty,\\[1ex]
\displaystyle  \sup_{0 \le x \le 1} \abs{f(x)}, & p=\infty,
\end{cases}
\\
\cv^{k}: =\cv^{k}[0,1]=\{f\in C[0,1]: \Var(f^{(k)}) < \infty \}, \\
\mathcal{W}^{k,p}=\mathcal{W}^{k,p}[0,1]=\{f\in C[0,1]: \|f^{(k)}\|_{p}<\infty\}.
\end{gather}
\end{subequations}
The stronger semi-norm is $\Fnorm{f}:=\Var(f''')$, while the weaker semi-norm is
\[
\Ftnorm{f}:=\norm[1]{f''-A_3(f)''}=\norm[1]{f''-4[f(1)-2f(1/2)+f(0)]}=\Var(f'-A_3(f)'),
\]
where $A_3(f): x \mapsto 2f(0)(x-1/2)(x-1)-4f(1/2)x(x-1)+2f(1)x(x-1/2)$ is the quadratic interpolant of $f$ using the middle point and two endpoints of the integration interval. The reason for defining $\Ftnorm{f}$ this way is that $\Ftnorm{f}$ vanishes if $f$ is a quadratic function, and quadratic functions are integrated exactly by the Simpson's rule.  The cone of integrands is defined as
\begin{equation}\label{coneinteg}
\cc_{\tau}:=\left\{f\in \cv^{3}:\begin{cases}
\displaystyle \Var(f''')\leq\tau\Var(f'')\\[2ex]
\displaystyle \Var(f'')\leq\tau\|f''-4[f(1)-2f(1/2)+f(0)]\|_1
\end{cases}\right\}.
\end{equation}

The algorithm for approximating $\norm[1]{f''-4[f(1)-2f(1/2)+f(0)]}$ is the $\tcf$-semi-norm of the quadratic spline, $A_n(f)$:
\begin{align}
\nonumber
\tF_n(f)&:=\Ftnorm{A_n(f)}=\bignorm[1]{A_n(f)''-A_3(f)''} \\
\label{1direst} \nonumber
&=\sum_{j=1}^{(n-1)/2}\int_{x_{2j-1}}^{x_{2j+1}}\left|A_n(f)''-A_3(f)''\right|\,\dif x, \\ \nonumber
&=\sum_{j=1}^{(n-1)/2}\int_{x_{2j-1}}^{x_{2j+1}}\left|(n-1)^2(f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})) - 4[f(1)-2f(1/2)+f(0)]\right|\,\dif x, \\ \nonumber
&=\sum_{j=1}^{(n-1)/2}\left|(n-1)^2(f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})) - 4[f(1)-2f(1/2)+f(0)]\right|(x_{2j+1}-x_{2j-1}), \\ \nonumber
&=\sum_{j=1}^{(n-1)/2}\left|(n-1)^2(f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})) - 4[f(1)-2f(1/2)+f(0)]\right|\frac{2}{n-1}, \\
&=\sum_{j=1}^{(n-1)/2}\left|2(n-1)(f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})) - \frac{8}{n-1}[f(1)-2f(1/2)+f(0)]\right|.
\end{align}
The variation of the second derivative of the quadratic spline of $f$, i.e.,
\begin{equation} \label{Fnormalg}
F_n(f) :=\Var(A_n(f)''') = (n-1)^2\sum_{j=1}^{(n-3)/2} \bigabs{f(x_{2j+3}) - 2 f(x_{2j+2})+2f(x_{2j})-f(x_{2j-1})},
\end{equation}
provides a lower bound on $\Var(f')$ for $n \ge 5$.

Constructing the adaptive algorithm for integration requires an upper bound on the error of $P_n$ and a two-sided bound on the error of $\tF_n$.  Note that $\tF_{n}(f)$ never overestimates $\Ftnorm{f}$ because
\begin{align*}
\Ftnorm{f} & = \bignorm[1]{f''-A_3(f)''}
= \sum_{j=1}^{(n-1)/2} \int_{x_{2j-1}}^{x_{2j+1}} \abs{f''(x) - A_3(f)''(x)} \, \dif x \\
& \ge \sum_{j=1}^{(n-1)/2} \abs{\int_{x_{2j-1}}^{x_{2j+1}} [f''(x) - A_3(f)''(x)] \, \dif x}=\norm[1]{A_n(f)''-A_3(f)''} = \tF_n(f).
\end{align*}
Thus, $h_{-}(n):=0$ and $\fc_n=\tfc_n=1$.

To find an upper bound on $\Ftnorm{f}-\tF_{n}(f)$, note that
\begin{equation*}
\Ftnorm{f} - \tF_{n}(f) = \Ftnorm{f} - \bigabs{A_n(f)}_{\tcf} \le \bigabs{f-A_n(f)}_{\tcf} = \bignorm[1]{f'' -A_n(f)''},
\end{equation*}
since $(f-A_n(f))(x)$ vanishes for $x=0,0.5,1$.  Moreover,
\begin{equation} \label{onenormfp}
\bignorm[1]{f'' -A_n(f)''} = \sum_{j=1}^{(n-1)/2} \int_{x_{2j-1}}^{x_{2j+1}} \abs{f''(x) -(n-1)^2[f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})]} \, \dif x.
\end{equation}
Now we bound each integral in the summation.  For $j=1, \ldots, (n-1)/2$, let $\eta_j(x) = f''(x) -(n-1)^2[f(x_{2j+1})-2f(x_{2j})+f(x_{2j-1})]$, and let $p_j$ denote the probability that $\eta_j(x)$ is non-negative:
\[
p_j = \frac{(n-1)}{2}\int_{x_{2j-1}}^{x_{2j+1}} \bbone_{[0,\infty)} (\eta_j(x)) \, \dif x,
\]
and so $1-p_j$ is the probability that $\eta_j(x)$ is negative.  

%Since $\int_{x_{2j-1}}^{x_{2j+1}} \eta_j(x) \, \dif x =0$, we know that $\eta_j$ must take on both non-positive and non-negative values.  Invoking the Mean Value Theorem, it follows that
%\begin{multline*}
%\frac{2p_j}{n-1} \sup_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) \ge \int_{x_{2j-1}}^{x_{2j+1}} \max(\eta_j(x),0) \, \dif x \\
%= \int_{x_{2j-1}}^{x_{2j+1}} \max(-\eta_j(x),0) \, \dif x \le \frac{-2(1-p_j)}{n-1} \inf_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) .
%\end{multline*}

It follows that
\begin{align*}
  \int_{x_{2j-1}}^{x_{2j+1}} \max(\eta_j(x),0) \, \dif x &\le \frac{2p_j}{n-1} \sup_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x),\\
  \int_{x_{2j-1}}^{x_{2j+1}} \max(-\eta_j(x),0) \, \dif x &\le \frac{-2(1-p_j)}{n-1} \inf_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) 
\end{align*}

These bounds allow us to derive bounds on the integrals in \eqref{onenormfp}:
\begin{align*}
\MoveEqLeft{\int_{x_{2j-1}}^{x_{2j+1}} \abs{\eta_j(x)} \, \dif x} \\
 &= \int_{x_{2j-1}}^{x_{2j+1}} \max(\eta_j(x),0) \, \dif x + \int_{x_{2j-1}}^{x_{2j+1}} \max(-\eta_j(x),0) \, \dif x\\
% &=4(1-p_j) \int_{x_{2j-1}}^{x_{2j+1}} \max(\eta_j(x),0) \, \dif x + 4p_j\int_{x_{2j-1}}^{x_{2j+1}} \max(-\eta_j(x),0) \, \dif x\\
&\le \frac{2p_i}{n-1} \sup_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) - \frac{2(1-p_i)}{n-1} \inf_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) \\
&\le \frac{2p_i(1-p_i)}{n-1} \left[ \sup_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) - \inf_{x_{2j-1} \le x \le x_{2j+1}} \eta_j(x) \right]\\
&\le\frac{1}{2(n-1)} \left[ \sup_{x_{2j-1} \le x \le x_{2j+1}} f''(x) - \inf_{x_{2j-1} \le x \le x_{2j+1}} f''(x) \right],
\end{align*}
since $p_i(1-p_i)\le 1/4$.

Plugging this bound into \eqref{onenormfp} yields
\begin{align*}
\bignorm[1]{f''-4[f(1)-2f(1/2)+f(0)]} - \tF_n(f) &= \Ftnorm{f} - \tF_{n}(f)\\
 & \le \bignorm[1]{f'' -A_n(f)''}\\
&\le \frac{1}{2(n-1)} \sum_{j=1}^{(n-1)/2} \left[ \sup_{x_{2j-1} \le x \le x_{2j+1}} f''(x) - \inf_{x_{2j-1} \le x \le x_{2j+1}} f''(x) \right] \\
& \le \frac{\Var(f'')}{2(n-1)} = \frac{\Fnorm{f}}{2(n-1)},
\end{align*}
and so
\begin{equation*}\label{factor}
h_{+}(n):= \frac{1}{2n-2}, \qquad \mathfrak{C}_n =\frac{1}{1 - \tau/(2n-2)} \qquad \text{for } n>1+\tau/2.
\end{equation*}
Since $\tF_3(f)=0$ by definition, the above inequality for $\Ftnorm{f} - \tF_{3}(f)$ implies that
\begin{equation*} \label{taumininteg}
4\bignorm[1]{f'-f(1)+f(0)} = 4 \Ftnorm{f} \le \Fnorm{f} = \Var(f'), \qquad \tau_{\min}=4.???
\end{equation*}

The error of the Simpson's rule in terms of the variation of the first derivative of the integrand is:
%\begin{subequations} \label{integhhtilde}
\begin{gather*}
\abs{\int_0^1 f(x) \, dx - P_n(f)} \le h(n) \Var(f''') \\
h(n):= \frac{1}{72(n-1)^4}, \qquad h^{-1}(\varepsilon) = \left \lceil \left(\frac{1}{72\varepsilon}\right)^{1/4} \right \rceil +1.
\end{gather*}
%\end{subequations}

Given the above definitions of $h, \fC_n, \fc_n$, and $\tfc_n$, it is now possible to also specify
\begin{subequations} \label{simplifycond}
\begin{gather}
h_1(n) = h_2(n) = \fC_n h(n) = \frac{1}{72(n-1)^3(n-1-\tau)}, \\
h_1^{-1}(\varepsilon) = h_2^{-1}(\varepsilon) = 1+ \left \lceil \sqrt{\frac{\tau}{8 \varepsilon} + \frac{\tau^2}{16}} +\frac{\tau}{4} \right \rceil \le 2 + \frac{\tau}{2} + \sqrt{\frac{\tau}{8\varepsilon}}.???
\end{gather}
Moreover, the left side of the stopping criterion inequality in the multi-stage algorithm, becomes
\begin{equation}
\tau h(n_i)\fC_{n_i} \tF_{n_i}(f) = \frac{\tau^2  \tF_{n_i}(f) } {36(n_i-1)^3(2n_i-2 -\tau)}.
\end{equation}
\end{subequations}
With these preliminaries, Algorithm \ref{multistagealgo} and Theorem \ref{MultiStageThm} may be applied directly to  yield the following adaptive integration algorithm and its guarantee.

\begin{algo}[Adaptive Univariate Integration] \label{multistageintegalgo}
Let the sequence of algorithms $\{P_n\}_{n\in \mathcal{I}}$, $\{\tF_n\}_{n\in \mathcal{I}}$, and $\{F_n\}_{n\in \mathcal{I}}$ be as described above.
Let $\tau\ge4$ be the cone constant. Set $i=1$. Let $n_1=2\lceil\tau/2\rceil+1$. For any error tolerance $\varepsilon$ and input function $f$, do the following:
\begin{description}
\item[Stage 1.\ Estimate {$\|f''-4[f(1)-2f(1/2)+f(0)]\|_1$} and bound {$\Var(f''')$}.] Compute $\tF_{n_i}(f)$ in \eqref{1direst} and $F_{n_i}(f)$ in \eqref{Fnormalg}.

\item[Stage 2. Check the necessary condition for $f \in \cc_{\tau}$.] Compute
    \begin{align*}
     \tau_{\min,n_i} =  \frac{F_{n_i}(f)}{\tF_{n_i}(f)+F_{n_i}(f)/(2n_i-2)}.
    \end{align*}
If $\tau \ge \tau_{\min,n_i}$, then go to stage 3.  Otherwise, set $\tau = 2\tau_{\min,n_i}$.  If $n_i \ge (\tau+1)/2$, then go to stage 3.  Otherwise, choose
$$
n_{i+1}=1+ (n_i-1)\left\lceil\frac{\tau+1}{n_i-1}\right\rceil.
$$
Go to Stage 1.

\item[Stage 3. Check for convergence.] Check whether $n_i$ is large enough to satisfy the error tolerance, i.e.
    \begin{equation*}
     \tF_{n_i}(f) \le \frac{36\varepsilon(n_i-1)^3(2n_i-2 - \tau)}{\tau}.
    \end{equation*}
If this is true, then return $T_{n_i}(f)$ and terminate the algorithm.   If this is not true, choose
$$
n_{i+1}=1+ (n_i-1)\max\left\{2,\left\lceil\frac{1}{(n_i-1)}\sqrt{\frac{\tau \tF_{n_i}(f)}{8\varepsilon}}\right\rceil\right\}.???
$$
Go to Stage 1.
\end{description}
\end{algo}


\end{document}

